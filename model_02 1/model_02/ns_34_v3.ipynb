{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "FIYNEzK3kGjP",
   "metadata": {
    "id": "FIYNEzK3kGjP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3fb598-79b9-4e6f-8957-03038537010e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee3fb598-79b9-4e6f-8957-03038537010e",
    "outputId": "5ca19deb-022b-4e8d-8f28-3845b9b0bab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the computational backend\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using: {device}')\n",
    "\n",
    "# Some helper functions for loading and saving trained models\n",
    "def load_model(path, model, optimizer, scheduler=None):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler is None: return model, optimizer\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "def save_model(path, model, optimizer, scheduler=None):\n",
    "    data = {'model_state_dict': model.state_dict()}\n",
    "    if optimizer is not None: data['optimizer_state_dict'] = optimizer.state_dict()\n",
    "    if scheduler is not None: data['scheduler_state_dict'] = scheduler.state_dict()\n",
    "    torch.save(data, path)\n",
    "\n",
    "# Some helper functions for retrieving CSV data (mesh and cfd results)\n",
    "def get_csv_data(path, category, batch_size):\n",
    "    if category == 'mesh':\n",
    "        x, y, z = np.loadtxt(path, delimiter=',', unpack=True)\n",
    "        x = torch.tensor(x, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "        y = torch.tensor(y, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "        z = torch.tensor(z, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "        return DataLoader(TensorDataset(x, y, z), batch_size=batch_size, shuffle=True)\n",
    "    elif category == 'cfd':\n",
    "        x, y, z, p, u, v, w = np.loadtxt(path, delimiter=',', unpack=True)\n",
    "        x = torch.tensor(x, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        y = torch.tensor(y, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        z = torch.tensor(z, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        u = torch.tensor(u, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        v = torch.tensor(v, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        w = torch.tensor(w, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        p = torch.tensor(p, dtype=torch.float, device=device).reshape(-1,1)\n",
    "        return DataLoader(TensorDataset(x, y, z, u, v, w, p), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def get_predictions(path, net_u, net_v, net_w, net_p):\n",
    "    x, y, z = np.loadtxt(path, delimiter=',', unpack=True)\n",
    "\n",
    "    res = np.zeros((len(x), 8))\n",
    "    res[:, 0] = x\n",
    "    res[:, 1] = y\n",
    "    res[:, 2] = z\n",
    "\n",
    "    x = torch.tensor(x, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "    y = torch.tensor(y, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "    z = torch.tensor(z, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
    "\n",
    "    # pred_u = net_u(x,y,z).cpu().detach().numpy()\n",
    "    # pred_v = net_v(x,y,z).cpu().detach().numpy()\n",
    "    # pred_w = net_w(x,y,z).cpu().detach().numpy()\n",
    "    # pred_p = net_p(x,y,z).cpu().detach().numpy()\n",
    "\n",
    "    res[:, 3] = net_p(x,y,z).cpu().detach().numpy()[:,0]\n",
    "    # res[:, 4]\n",
    "    res[:, 5] = net_u(x,y,z).cpu().detach().numpy()[:,0]\n",
    "    res[:, 6] = net_v(x,y,z).cpu().detach().numpy()[:,0]\n",
    "    res[:, 7] = net_w(x,y,z).cpu().detach().numpy()[:,0]\n",
    "\n",
    "    # return pred_u, pred_v, pred_w, pred_p\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb526e9e-743e-4bd3-a605-d81e1b1b9a24",
   "metadata": {
    "id": "fb526e9e-743e-4bd3-a605-d81e1b1b9a24"
   },
   "outputs": [],
   "source": [
    "# The neural network. Represents a function for \\R^3 to \\R\n",
    "class NSNeuralNet(nn.Module):\n",
    "    def __init__(self, width=256):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(3,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,width),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(width,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y, z):\n",
    "        return self.main(torch.cat([x, y, z], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ef02a8-906f-45bb-8bcb-f670047a198f",
   "metadata": {
    "id": "20ef02a8-906f-45bb-8bcb-f670047a198f"
   },
   "outputs": [],
   "source": [
    "# Setup the neural network, the optimizer, the learning rate scheduler, ...\n",
    "\n",
    "model_u = NSNeuralNet().to(device)\n",
    "model_v = NSNeuralNet().to(device)\n",
    "model_w = NSNeuralNet().to(device)\n",
    "model_p = NSNeuralNet().to(device)\n",
    "\n",
    "model_u.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
    "model_v.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
    "model_w.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
    "model_p.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xPj9FCd1zIJh",
   "metadata": {
    "id": "xPj9FCd1zIJh"
   },
   "outputs": [],
   "source": [
    "optimizer_u = optim.Adam(model_u.parameters(), lr=0.1*1e-3)\n",
    "optimizer_v = optim.Adam(model_v.parameters(), lr=0.1*1e-3)\n",
    "optimizer_w = optim.Adam(model_w.parameters(), lr=0.1*1e-3)\n",
    "optimizer_p = optim.Adam(model_p.parameters(), lr=0.1*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447de6ce-f4f4-4a60-a05e-ed034f813ef2",
   "metadata": {
    "id": "447de6ce-f4f4-4a60-a05e-ed034f813ef2"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ns_34_u.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load a pretrained model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model_u, optimizer_u \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mns_34_u.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_u\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model_v, optimizer_v \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns_34_v.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, model_v, optimizer_v)\n\u001b[0;32m      5\u001b[0m model_w, optimizer_w \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns_34_w.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, model_w, optimizer_w)\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(path, model, optimizer, scheduler)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(path, model, optimizer, scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 7\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ns_34_u.pt'"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model\n",
    "\n",
    "model_u, optimizer_u = load_model('ns_34_u.pt', model_u, optimizer_u)\n",
    "model_v, optimizer_v = load_model('ns_34_v.pt', model_v, optimizer_v)\n",
    "model_w, optimizer_w = load_model('ns_34_w.pt', model_w, optimizer_w)\n",
    "model_p, optimizer_p = load_model('ns_34_p.pt', model_p, optimizer_p)\n",
    "\n",
    "model_u.train();\n",
    "model_v.train();\n",
    "model_w.train();\n",
    "model_p.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e6a694-7d0a-4fe6-b9e7-13f8282e5c3e",
   "metadata": {
    "id": "81e6a694-7d0a-4fe6-b9e7-13f8282e5c3e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "mesh_small_case_1.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m batch_mesh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[0;32m      5\u001b[0m batch_cfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2500\u001b[39m\n\u001b[1;32m----> 7\u001b[0m mesh_ds \u001b[38;5;241m=\u001b[39m \u001b[43mget_csv_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_mesh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmesh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mesh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m cfd_ds \u001b[38;5;241m=\u001b[39m get_csv_data(file_cfd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfd\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_cfd)\n",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m, in \u001b[0;36mget_csv_data\u001b[1;34m(path, category, batch_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_csv_data\u001b[39m(path, category, batch_size):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m category \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 23\u001b[0m         x, y, z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m         y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\numpy\\lib\\npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1354\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1356\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\numpy\\lib\\npyio.py:975\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    973\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 975\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\olarinoyem\\AppData\\Local\\miniconda3\\envs\\pyt_env\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: mesh_small_case_1.csv not found."
     ]
    }
   ],
   "source": [
    "# Domain of the PDE (the mesh stuff)\n",
    "file_mesh = 'mesh_small_case_1.csv'\n",
    "file_cfd = 'cfd_case_1_sample_1.csv'\n",
    "batch_mesh = 5000\n",
    "batch_cfd = 2500\n",
    "\n",
    "mesh_ds = get_csv_data(file_mesh, 'mesh', batch_mesh)\n",
    "cfd_ds = get_csv_data(file_cfd, 'cfd', batch_cfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b39d33-b481-4072-8003-08faf876f8a8",
   "metadata": {
    "id": "d3b39d33-b481-4072-8003-08faf876f8a8"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "lambda_data = 10.0\n",
    "\n",
    "rho = 1050 # density\n",
    "mu = 0.0035 # viscosity\n",
    "\n",
    "# Define the loss components due to the NS equations\n",
    "def loss_physics(net_u, net_v, net_w, net_p, x, y, z):\n",
    "    u = net_u(x, y, z)\n",
    "    v = net_v(x, y, z)\n",
    "    w = net_w(x, y, z)\n",
    "    p = net_p(x, y, z)\n",
    "\n",
    "    p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "    p_z = torch.autograd.grad(p, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    w_x = torch.autograd.grad(w, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "\n",
    "    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "    w_y = torch.autograd.grad(w, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "\n",
    "    u_z = torch.autograd.grad(u, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "    v_z = torch.autograd.grad(v, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "    w_z = torch.autograd.grad(w, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    w_xx = torch.autograd.grad(w_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "\n",
    "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "    w_yy = torch.autograd.grad(w_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "\n",
    "    u_zz = torch.autograd.grad(u_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "    v_zz = torch.autograd.grad(v_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "    w_zz = torch.autograd.grad(w_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
    "\n",
    "    eqn_x = p_x + rho * (u*u_x + v*u_y + w*u_z) - mu * (u_xx + u_yy + u_zz)\n",
    "    eqn_y = p_y + rho * (u*v_x + v*v_y + w*v_z) - mu * (v_xx + v_yy + v_zz)\n",
    "    eqn_z = p_z + rho * (u*w_x + v*w_y + w*w_z) - mu * (w_xx + w_yy + w_zz)\n",
    "    eqn_c = u_x + v_y + w_z\n",
    "\n",
    "    eqn = eqn_x + eqn_y + eqn_z + eqn_c\n",
    "    return loss_func(eqn, torch.zeros_like(eqn))\n",
    "\n",
    "# Define the loss due to data fitting (regularisation)\n",
    "def loss_data(net_u, net_v, net_w, net_p, x, y, z, u, v, w, p):\n",
    "    cpt_u = loss_func(net_u(x, y, z), u)\n",
    "    cpt_v = loss_func(net_v(x, y, z), v)\n",
    "    cpt_w = loss_func(net_w(x, y, z), w)\n",
    "    cpt_p = loss_func(net_p(x, y, z), p)\n",
    "    return cpt_u + cpt_v + cpt_w + cpt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f067b2-a6f4-4546-94f1-932cc4934144",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4f067b2-a6f4-4546-94f1-932cc4934144",
    "outputId": "3676f610-fb15-4222-ee58-5c8982555a40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = Loss due to physics (NS equations)\n",
      "D = Loss due to data fitting\n",
      "T = Total loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       5 / 200     ]    P(   0.0419895 )    D(   0.2522198 )    T(   2.5641873 )\n",
      "[      10 / 200     ]    P(   0.0049560 )    D(   0.2415206 )    T(   2.4201622 )\n",
      "[      15 / 200     ]    P(   0.0018223 )    D(   0.2392178 )    T(   2.3940001 )\n",
      "[      20 / 200     ]    P(   0.0013844 )    D(   0.2388716 )    T(   2.3901002 )\n",
      "[      25 / 200     ]    P(   0.0155211 )    D(   0.2390309 )    T(   2.4058297 )\n",
      "[      30 / 200     ]    P(   0.0086552 )    D(   0.2404910 )    T(   2.4135656 )\n",
      "[      35 / 200     ]    P(   0.0011863 )    D(   0.2374698 )    T(   2.3758841 )\n",
      "[      40 / 200     ]    P(   0.0027596 )    D(   0.2380478 )    T(   2.3832374 )\n",
      "[      45 / 200     ]    P(   0.0021021 )    D(   0.2372353 )    T(   2.3744547 )\n",
      "[      50 / 200     ]    P(   0.0130470 )    D(   0.2378717 )    T(   2.3917639 )\n",
      "[      55 / 200     ]    P(   0.0017009 )    D(   0.2363320 )    T(   2.3650205 )\n",
      "[      60 / 200     ]    P(   0.0010208 )    D(   0.2357431 )    T(   2.3584516 )\n",
      "[      65 / 200     ]    P(   0.0095400 )    D(   0.2376008 )    T(   2.3855476 )\n",
      "[      70 / 200     ]    P(   0.0058211 )    D(   0.2349192 )    T(   2.3550131 )\n",
      "[      75 / 200     ]    P(   0.0025975 )    D(   0.2348941 )    T(   2.3515387 )\n",
      "[      80 / 200     ]    P(   0.0463090 )    D(   0.2506160 )    T(   2.5524693 )\n",
      "[      85 / 200     ]    P(   0.0065625 )    D(   0.2344448 )    T(   2.3510106 )\n",
      "[      90 / 200     ]    P(   0.0020168 )    D(   0.2338387 )    T(   2.3404038 )\n",
      "[      95 / 200     ]    P(   0.0019908 )    D(   0.2328697 )    T(   2.3306875 )\n",
      "[     100 / 200     ]    P(   0.0444018 )    D(   0.2358252 )    T(   2.4026544 )\n",
      "[     105 / 200     ]    P(   0.0233988 )    D(   0.2317016 )    T(   2.3404150 )\n",
      "[     110 / 200     ]    P(   0.0150610 )    D(   0.2313288 )    T(   2.3283491 )\n",
      "[     115 / 200     ]    P(   0.1649676 )    D(   0.2336907 )    T(   2.5018744 )\n",
      "[     120 / 200     ]    P(   0.0048471 )    D(   0.2315426 )    T(   2.3202727 )\n",
      "[     125 / 200     ]    P(   0.0029430 )    D(   0.2304374 )    T(   2.3073170 )\n",
      "[     130 / 200     ]    P(   0.0022399 )    D(   0.2298177 )    T(   2.3004167 )\n",
      "[     135 / 200     ]    P(   0.4593012 )    D(   0.2654593 )    T(   3.1138940 )\n",
      "[     140 / 200     ]    P(   0.0456351 )    D(   0.2309005 )    T(   2.3546402 )\n",
      "[     145 / 200     ]    P(   0.0078136 )    D(   0.2292063 )    T(   2.2998765 )\n",
      "[     150 / 200     ]    P(   0.0068148 )    D(   0.2283391 )    T(   2.2902052 )\n",
      "[     155 / 200     ]    P(   0.0042301 )    D(   0.2274812 )    T(   2.2790422 )\n",
      "[     160 / 200     ]    P(   0.0826973 )    D(   0.2348849 )    T(   2.4315462 )\n",
      "[     165 / 200     ]    P(   0.0083097 )    D(   0.2296558 )    T(   2.3048675 )\n",
      "[     170 / 200     ]    P(   0.0085058 )    D(   0.2259972 )    T(   2.2684777 )\n",
      "[     175 / 200     ]    P(   0.0036334 )    D(   0.2244200 )    T(   2.2478340 )\n",
      "[     180 / 200     ]    P(   0.7474820 )    D(   0.2970516 )    T(   3.7179985 )\n",
      "[     185 / 200     ]    P(   0.0252679 )    D(   0.2278069 )    T(   2.3033371 )\n",
      "[     190 / 200     ]    P(   0.0066979 )    D(   0.2264912 )    T(   2.2716098 )\n",
      "[     195 / 200     ]    P(   0.0046021 )    D(   0.2235744 )    T(   2.2403464 )\n",
      "[     200 / 200     ]    P(   0.0037680 )    D(   0.2198031 )    T(   2.2017984 )\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 200 # ideally around 10_000\n",
    "\n",
    "print('P = Loss due to physics (NS equations)')\n",
    "print('D = Loss due to data fitting')\n",
    "print('T = Total loss')\n",
    "\n",
    "def display_state(epochs_done, epochs_total, loss_phys, loss_data, loss_total):\n",
    "    with torch.autograd.no_grad():\n",
    "        msg = f'[{epochs_done:>8} / {epochs_total:<8}]'\n",
    "        msg += f'    P( {loss_phys:>11.7f} )'\n",
    "        msg += f'    D( {loss_data:>11.7f} )'\n",
    "        msg += f'    T( {loss_total:>11.7f} )'\n",
    "        print(msg)\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    for xm, ym, zm in mesh_ds:\n",
    "        for xd, yd, zd, ud, vd, wd, pd in cfd_ds:\n",
    "            l_phys = loss_physics(model_u, model_v, model_w, model_p, xm, ym, zm)\n",
    "            l_data = loss_data(model_u, model_v, model_w, model_p, xd, yd, zd, ud, vd, wd, pd)\n",
    "            l_total = l_phys + lambda_data * l_data\n",
    "\n",
    "            optimizer_u.zero_grad()\n",
    "            optimizer_v.zero_grad()\n",
    "            optimizer_w.zero_grad()\n",
    "            optimizer_p.zero_grad()\n",
    "\n",
    "            l_total.backward()\n",
    "\n",
    "            optimizer_u.step()\n",
    "            optimizer_v.step()\n",
    "            optimizer_w.step()\n",
    "            optimizer_p.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        display_state(epoch, epochs, l_phys, l_data, l_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49dd466-c5be-4aa0-854e-6fc66b85d236",
   "metadata": {
    "id": "e49dd466-c5be-4aa0-854e-6fc66b85d236"
   },
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "\n",
    "save_model('ns_34_u.pt', model_u, optimizer_u)\n",
    "save_model('ns_34_v.pt', model_v, optimizer_v)\n",
    "save_model('ns_34_w.pt', model_w, optimizer_w)\n",
    "save_model('ns_34_p.pt', model_p, optimizer_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yPjVxbEukRK7",
   "metadata": {
    "id": "yPjVxbEukRK7"
   },
   "outputs": [],
   "source": [
    "# # Use the trained model to generate the velocity and pressure fields\n",
    "\n",
    "dt = get_predictions('calc_mesh.csv', model_u, model_v, model_w, model_p)\n",
    "np.savetxt('1_xz_full_pinn.csv', dt, delimiter=',', fmt='%.8e')\n",
    "\n",
    "# # Make plots, or export to VTK etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3jxQdmeHIrhK",
   "metadata": {
    "id": "3jxQdmeHIrhK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
