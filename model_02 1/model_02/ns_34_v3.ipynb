{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FIYNEzK3kGjP"
      },
      "id": "FIYNEzK3kGjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee3fb598-79b9-4e6f-8957-03038537010e",
      "metadata": {
        "id": "ee3fb598-79b9-4e6f-8957-03038537010e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca19deb-022b-4e8d-8f28-3845b9b0bab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set the computational backend\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using: {device}')\n",
        "\n",
        "# Some helper functions for loading and saving trained models\n",
        "def load_model(path, model, optimizer, scheduler=None):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler is None: return model, optimizer\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    return model, optimizer, scheduler\n",
        "\n",
        "def save_model(path, model, optimizer, scheduler=None):\n",
        "    data = {'model_state_dict': model.state_dict()}\n",
        "    if optimizer is not None: data['optimizer_state_dict'] = optimizer.state_dict()\n",
        "    if scheduler is not None: data['scheduler_state_dict'] = scheduler.state_dict()\n",
        "    torch.save(data, path)\n",
        "\n",
        "# Some helper functions for retrieving CSV data (mesh and cfd results)\n",
        "def get_csv_data(path, category, batch_size):\n",
        "    if category == 'mesh':\n",
        "        x, y, z = np.loadtxt(path, delimiter=',', unpack=True)\n",
        "        x = torch.tensor(x, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "        y = torch.tensor(y, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "        z = torch.tensor(z, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "        return DataLoader(TensorDataset(x, y, z), batch_size=batch_size, shuffle=True)\n",
        "    elif category == 'cfd':\n",
        "        x, y, z, p, u, v, w = np.loadtxt(path, delimiter=',', unpack=True)\n",
        "        x = torch.tensor(x, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        y = torch.tensor(y, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        z = torch.tensor(z, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        u = torch.tensor(u, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        v = torch.tensor(v, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        w = torch.tensor(w, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        p = torch.tensor(p, dtype=torch.float, device=device).reshape(-1,1)\n",
        "        return DataLoader(TensorDataset(x, y, z, u, v, w, p), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "def get_predictions(path, net_u, net_v, net_w, net_p):\n",
        "    x, y, z = np.loadtxt(path, delimiter=',', unpack=True)\n",
        "\n",
        "    res = np.zeros((len(x), 8))\n",
        "    res[:, 0] = x\n",
        "    res[:, 1] = y\n",
        "    res[:, 2] = z\n",
        "\n",
        "    x = torch.tensor(x, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "    y = torch.tensor(y, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "    z = torch.tensor(z, dtype=torch.float, requires_grad=True, device=device).reshape(-1,1)\n",
        "\n",
        "    # pred_u = net_u(x,y,z).cpu().detach().numpy()\n",
        "    # pred_v = net_v(x,y,z).cpu().detach().numpy()\n",
        "    # pred_w = net_w(x,y,z).cpu().detach().numpy()\n",
        "    # pred_p = net_p(x,y,z).cpu().detach().numpy()\n",
        "\n",
        "    res[:, 3] = net_p(x,y,z).cpu().detach().numpy()[:,0]\n",
        "    # res[:, 4]\n",
        "    res[:, 5] = net_u(x,y,z).cpu().detach().numpy()[:,0]\n",
        "    res[:, 6] = net_v(x,y,z).cpu().detach().numpy()[:,0]\n",
        "    res[:, 7] = net_w(x,y,z).cpu().detach().numpy()[:,0]\n",
        "\n",
        "    # return pred_u, pred_v, pred_w, pred_p\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb526e9e-743e-4bd3-a605-d81e1b1b9a24",
      "metadata": {
        "id": "fb526e9e-743e-4bd3-a605-d81e1b1b9a24"
      },
      "outputs": [],
      "source": [
        "# The neural network. Represents a function for \\R^3 to \\R\n",
        "class NSNeuralNet(nn.Module):\n",
        "    def __init__(self, width=256):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(3,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,width),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(width,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y, z):\n",
        "        return self.main(torch.cat([x, y, z], axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ef02a8-906f-45bb-8bcb-f670047a198f",
      "metadata": {
        "id": "20ef02a8-906f-45bb-8bcb-f670047a198f"
      },
      "outputs": [],
      "source": [
        "# Setup the neural network, the optimizer, the learning rate scheduler, ...\n",
        "\n",
        "model_u = NSNeuralNet().to(device)\n",
        "model_v = NSNeuralNet().to(device)\n",
        "model_w = NSNeuralNet().to(device)\n",
        "model_p = NSNeuralNet().to(device)\n",
        "\n",
        "model_u.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
        "model_v.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
        "model_w.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);\n",
        "model_p.apply(lambda m: nn.init.kaiming_normal_(m.weight) if type(m) == nn.Linear else None);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_u = optim.Adam(model_u.parameters(), lr=0.1*1e-3)\n",
        "optimizer_v = optim.Adam(model_v.parameters(), lr=0.1*1e-3)\n",
        "optimizer_w = optim.Adam(model_w.parameters(), lr=0.1*1e-3)\n",
        "optimizer_p = optim.Adam(model_p.parameters(), lr=0.1*1e-3)"
      ],
      "metadata": {
        "id": "xPj9FCd1zIJh"
      },
      "id": "xPj9FCd1zIJh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "447de6ce-f4f4-4a60-a05e-ed034f813ef2",
      "metadata": {
        "id": "447de6ce-f4f4-4a60-a05e-ed034f813ef2"
      },
      "outputs": [],
      "source": [
        "# Load a pretrained model\n",
        "\n",
        "model_u, optimizer_u = load_model('ns_34_u.pt', model_u, optimizer_u)\n",
        "model_v, optimizer_v = load_model('ns_34_v.pt', model_v, optimizer_v)\n",
        "model_w, optimizer_w = load_model('ns_34_w.pt', model_w, optimizer_w)\n",
        "model_p, optimizer_p = load_model('ns_34_p.pt', model_p, optimizer_p)\n",
        "\n",
        "model_u.train();\n",
        "model_v.train();\n",
        "model_w.train();\n",
        "model_p.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e6a694-7d0a-4fe6-b9e7-13f8282e5c3e",
      "metadata": {
        "id": "81e6a694-7d0a-4fe6-b9e7-13f8282e5c3e"
      },
      "outputs": [],
      "source": [
        "# Domain of the PDE (the mesh stuff)\n",
        "file_mesh = 'mesh_small_case_1.csv'\n",
        "file_cfd = 'cfd_case_1_sample_1.csv'\n",
        "batch_mesh = 5000\n",
        "batch_cfd = 2500\n",
        "\n",
        "mesh_ds = get_csv_data(file_mesh, 'mesh', batch_mesh)\n",
        "cfd_ds = get_csv_data(file_cfd, 'cfd', batch_cfd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b39d33-b481-4072-8003-08faf876f8a8",
      "metadata": {
        "id": "d3b39d33-b481-4072-8003-08faf876f8a8"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.MSELoss()\n",
        "lambda_data = 10.0\n",
        "\n",
        "rho = 1050 # density\n",
        "mu = 0.0035 # viscosity\n",
        "\n",
        "# Define the loss components due to the NS equations\n",
        "def loss_physics(net_u, net_v, net_w, net_p, x, y, z):\n",
        "    u = net_u(x, y, z)\n",
        "    v = net_v(x, y, z)\n",
        "    w = net_w(x, y, z)\n",
        "    p = net_p(x, y, z)\n",
        "\n",
        "    p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "    p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "    p_z = torch.autograd.grad(p, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "    v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "    w_x = torch.autograd.grad(w, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "\n",
        "    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "    v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "    w_y = torch.autograd.grad(w, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "\n",
        "    u_z = torch.autograd.grad(u, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "    v_z = torch.autograd.grad(v, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "    w_z = torch.autograd.grad(w, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "    w_xx = torch.autograd.grad(w_x, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
        "\n",
        "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "    w_yy = torch.autograd.grad(w_y, y, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
        "\n",
        "    u_zz = torch.autograd.grad(u_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "    v_zz = torch.autograd.grad(v_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "    w_zz = torch.autograd.grad(w_z, z, grad_outputs=torch.ones_like(z), create_graph=True)[0]\n",
        "\n",
        "    eqn_x = p_x + rho * (u*u_x + v*u_y + w*u_z) - mu * (u_xx + u_yy + u_zz)\n",
        "    eqn_y = p_y + rho * (u*v_x + v*v_y + w*v_z) - mu * (v_xx + v_yy + v_zz)\n",
        "    eqn_z = p_z + rho * (u*w_x + v*w_y + w*w_z) - mu * (w_xx + w_yy + w_zz)\n",
        "    eqn_c = u_x + v_y + w_z\n",
        "\n",
        "    eqn = eqn_x + eqn_y + eqn_z + eqn_c\n",
        "    return loss_func(eqn, torch.zeros_like(eqn))\n",
        "\n",
        "# Define the loss due to data fitting (regularisation)\n",
        "def loss_data(net_u, net_v, net_w, net_p, x, y, z, u, v, w, p):\n",
        "    cpt_u = loss_func(net_u(x, y, z), u)\n",
        "    cpt_v = loss_func(net_v(x, y, z), v)\n",
        "    cpt_w = loss_func(net_w(x, y, z), w)\n",
        "    cpt_p = loss_func(net_p(x, y, z), p)\n",
        "    return cpt_u + cpt_v + cpt_w + cpt_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f067b2-a6f4-4546-94f1-932cc4934144",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4f067b2-a6f4-4546-94f1-932cc4934144",
        "outputId": "3676f610-fb15-4222-ee58-5c8982555a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P = Loss due to physics (NS equations)\n",
            "D = Loss due to data fitting\n",
            "T = Total loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[       5 / 200     ]    P(   0.0419895 )    D(   0.2522198 )    T(   2.5641873 )\n",
            "[      10 / 200     ]    P(   0.0049560 )    D(   0.2415206 )    T(   2.4201622 )\n",
            "[      15 / 200     ]    P(   0.0018223 )    D(   0.2392178 )    T(   2.3940001 )\n",
            "[      20 / 200     ]    P(   0.0013844 )    D(   0.2388716 )    T(   2.3901002 )\n",
            "[      25 / 200     ]    P(   0.0155211 )    D(   0.2390309 )    T(   2.4058297 )\n",
            "[      30 / 200     ]    P(   0.0086552 )    D(   0.2404910 )    T(   2.4135656 )\n",
            "[      35 / 200     ]    P(   0.0011863 )    D(   0.2374698 )    T(   2.3758841 )\n",
            "[      40 / 200     ]    P(   0.0027596 )    D(   0.2380478 )    T(   2.3832374 )\n",
            "[      45 / 200     ]    P(   0.0021021 )    D(   0.2372353 )    T(   2.3744547 )\n",
            "[      50 / 200     ]    P(   0.0130470 )    D(   0.2378717 )    T(   2.3917639 )\n",
            "[      55 / 200     ]    P(   0.0017009 )    D(   0.2363320 )    T(   2.3650205 )\n",
            "[      60 / 200     ]    P(   0.0010208 )    D(   0.2357431 )    T(   2.3584516 )\n",
            "[      65 / 200     ]    P(   0.0095400 )    D(   0.2376008 )    T(   2.3855476 )\n",
            "[      70 / 200     ]    P(   0.0058211 )    D(   0.2349192 )    T(   2.3550131 )\n",
            "[      75 / 200     ]    P(   0.0025975 )    D(   0.2348941 )    T(   2.3515387 )\n",
            "[      80 / 200     ]    P(   0.0463090 )    D(   0.2506160 )    T(   2.5524693 )\n",
            "[      85 / 200     ]    P(   0.0065625 )    D(   0.2344448 )    T(   2.3510106 )\n",
            "[      90 / 200     ]    P(   0.0020168 )    D(   0.2338387 )    T(   2.3404038 )\n",
            "[      95 / 200     ]    P(   0.0019908 )    D(   0.2328697 )    T(   2.3306875 )\n",
            "[     100 / 200     ]    P(   0.0444018 )    D(   0.2358252 )    T(   2.4026544 )\n",
            "[     105 / 200     ]    P(   0.0233988 )    D(   0.2317016 )    T(   2.3404150 )\n",
            "[     110 / 200     ]    P(   0.0150610 )    D(   0.2313288 )    T(   2.3283491 )\n",
            "[     115 / 200     ]    P(   0.1649676 )    D(   0.2336907 )    T(   2.5018744 )\n",
            "[     120 / 200     ]    P(   0.0048471 )    D(   0.2315426 )    T(   2.3202727 )\n",
            "[     125 / 200     ]    P(   0.0029430 )    D(   0.2304374 )    T(   2.3073170 )\n",
            "[     130 / 200     ]    P(   0.0022399 )    D(   0.2298177 )    T(   2.3004167 )\n",
            "[     135 / 200     ]    P(   0.4593012 )    D(   0.2654593 )    T(   3.1138940 )\n",
            "[     140 / 200     ]    P(   0.0456351 )    D(   0.2309005 )    T(   2.3546402 )\n",
            "[     145 / 200     ]    P(   0.0078136 )    D(   0.2292063 )    T(   2.2998765 )\n",
            "[     150 / 200     ]    P(   0.0068148 )    D(   0.2283391 )    T(   2.2902052 )\n",
            "[     155 / 200     ]    P(   0.0042301 )    D(   0.2274812 )    T(   2.2790422 )\n",
            "[     160 / 200     ]    P(   0.0826973 )    D(   0.2348849 )    T(   2.4315462 )\n",
            "[     165 / 200     ]    P(   0.0083097 )    D(   0.2296558 )    T(   2.3048675 )\n",
            "[     170 / 200     ]    P(   0.0085058 )    D(   0.2259972 )    T(   2.2684777 )\n",
            "[     175 / 200     ]    P(   0.0036334 )    D(   0.2244200 )    T(   2.2478340 )\n",
            "[     180 / 200     ]    P(   0.7474820 )    D(   0.2970516 )    T(   3.7179985 )\n",
            "[     185 / 200     ]    P(   0.0252679 )    D(   0.2278069 )    T(   2.3033371 )\n",
            "[     190 / 200     ]    P(   0.0066979 )    D(   0.2264912 )    T(   2.2716098 )\n",
            "[     195 / 200     ]    P(   0.0046021 )    D(   0.2235744 )    T(   2.2403464 )\n",
            "[     200 / 200     ]    P(   0.0037680 )    D(   0.2198031 )    T(   2.2017984 )\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "epochs = 200 # ideally around 10_000\n",
        "\n",
        "print('P = Loss due to physics (NS equations)')\n",
        "print('D = Loss due to data fitting')\n",
        "print('T = Total loss')\n",
        "\n",
        "def display_state(epochs_done, epochs_total, loss_phys, loss_data, loss_total):\n",
        "    with torch.autograd.no_grad():\n",
        "        msg = f'[{epochs_done:>8} / {epochs_total:<8}]'\n",
        "        msg += f'    P( {loss_phys:>11.7f} )'\n",
        "        msg += f'    D( {loss_data:>11.7f} )'\n",
        "        msg += f'    T( {loss_total:>11.7f} )'\n",
        "        print(msg)\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "    for xm, ym, zm in mesh_ds:\n",
        "        for xd, yd, zd, ud, vd, wd, pd in cfd_ds:\n",
        "            l_phys = loss_physics(model_u, model_v, model_w, model_p, xm, ym, zm)\n",
        "            l_data = loss_data(model_u, model_v, model_w, model_p, xd, yd, zd, ud, vd, wd, pd)\n",
        "            l_total = l_phys + lambda_data * l_data\n",
        "\n",
        "            optimizer_u.zero_grad()\n",
        "            optimizer_v.zero_grad()\n",
        "            optimizer_w.zero_grad()\n",
        "            optimizer_p.zero_grad()\n",
        "\n",
        "            l_total.backward()\n",
        "\n",
        "            optimizer_u.step()\n",
        "            optimizer_v.step()\n",
        "            optimizer_w.step()\n",
        "            optimizer_p.step()\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        display_state(epoch, epochs, l_phys, l_data, l_total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e49dd466-c5be-4aa0-854e-6fc66b85d236",
      "metadata": {
        "id": "e49dd466-c5be-4aa0-854e-6fc66b85d236"
      },
      "outputs": [],
      "source": [
        "# # Save the trained model\n",
        "\n",
        "save_model('ns_34_u.pt', model_u, optimizer_u)\n",
        "save_model('ns_34_v.pt', model_v, optimizer_v)\n",
        "save_model('ns_34_w.pt', model_w, optimizer_w)\n",
        "save_model('ns_34_p.pt', model_p, optimizer_p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the trained model to generate the velocity and pressure fields\n",
        "\n",
        "dt = get_predictions('calc_mesh.csv', model_u, model_v, model_w, model_p)\n",
        "np.savetxt('1_xz_full_pinn.csv', dt, delimiter=',', fmt='%.8e')\n",
        "\n",
        "# # Make plots, or export to VTK etc"
      ],
      "metadata": {
        "id": "yPjVxbEukRK7"
      },
      "id": "yPjVxbEukRK7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3jxQdmeHIrhK"
      },
      "id": "3jxQdmeHIrhK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}